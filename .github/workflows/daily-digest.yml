name: Update and Deploy to GitHub Pages

# IF we push a backend/config change we want to cancel any running generation,
# pushing the code change itself will start a enw one.
concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true 


# Run every 2 hours (adjust cron as needed)
on:
  schedule:
    - cron: '0 */2 * * *'  # Every 2 hours, on the hour (UTC)
  # Allow manual triggering
  workflow_dispatch:
  # Run on pushes to main branch
  push:
    branches: [ main ]

permissions:
  contents: write  # Allow pushing commits back to repository
  pages: write     # Allow deploying to GitHub Pages
  id-token: write  # Allow OIDC token for Pages deployment

jobs:
  generate-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: latest
        
    - name: Install Python dependencies
      run: poetry install
      
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
        
    - name: Install Node.js dependencies
      run: cd frontend && npm ci
      
    - name: Cache LLM model
      uses: actions/cache@v4
      id: model-cache
      with:
        path: models/phi-2.Q4_0.gguf
        key: phi-2-model-v1
        
    - name: Download LLM model
      if: steps.model-cache.outputs.cache-hit != 'true'
      run: |
        mkdir -p models
        # Use huggingface-cli download (same command that works locally)
        poetry run huggingface-cli download QuantFactory/phi-2-GGUF phi-2.Q4_0.gguf \
          --local-dir ./models --local-dir-use-symlinks False
        
        # Verify the file was downloaded and has reasonable size (should be > 1GB)
        if [ -f models/phi-2.Q4_0.gguf ] && [ $(stat -c%s models/phi-2.Q4_0.gguf) -gt 1000000000 ]; then
          echo "Model downloaded successfully ($(ls -lh models/phi-2.Q4_0.gguf | awk '{print $5}'))"
        else
          echo "Model download failed or file too small"
          exit 1
        fi
      
    - name: Generate news digest
      run: poetry run python backend/generate_news_digest.py
      
    - name: Commit updated cache database
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add backend/processing_cache.db
        if ! git diff --staged --quiet; then
          git commit -m "Update cache database after daily digest generation [skip ci]"
          git push
        fi
      
    - name: Copy topic JSON files to React public folder
      run: |
        mkdir -p frontend/public/topics
        cp backend/topics/*.json frontend/public/topics/
      
    - name: Build frontend
      run: |
        cd frontend
        npm install
        npm run build
      
    - name: Copy topic JSON files to build folder
      run: |
        mkdir -p frontend/build/topics
        cp backend/topics/*.json frontend/build/topics/
      
    - name: Setup Pages
      uses: actions/configure-pages@v4
      
    - name: Upload to GitHub Pages
      uses: actions/upload-pages-artifact@v3
      with:
        path: ./frontend/build
        
    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
